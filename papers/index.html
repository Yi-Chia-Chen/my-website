<!DOCTYPE html>
<html lang='en-US'>

<head>
    <title>Papers - YCC</title>
    <meta name='keywords' content='Psychology, Perception, Vision, Yale, Harvard, UCLA' />
    <meta name='author' content='Yi-Chia Chen 陳怡嘉' />
    <meta name='viewport' content='width=device-width, initial-scale=1.0' />
    <meta name='description' content='Research publications by Yi-Chia Chen' />
    <link rel='shortcut icon' href='../files/images/favicon-32x32.png' />
    <link rel='stylesheet' href='../style.css' />

    <link rel='stylesheet' href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel='preconnect' href="https://fonts.googleapis.com">
    <link rel='preconnect' href="https://fonts.gstatic.com" crossorigin>
    <link href='https://fonts.googleapis.com/css2?family=Cinzel:wght@500&family=Raleway:ital,wght@0,100..900;1,100..900&display=swap' rel="stylesheet">
    <script src='https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js'></script>
    <script src='https://kit.fontawesome.com/12eb5bce58.js'></script>
</head>

<body>
    <header>
        <a class='title' href='..'>Yi-Chia Chen</a>
    </header>
    <nav>
        <div class='nav-button-small' id='secret-button-left'>
            <svg class='tight' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'>
                <polygon class='nav-triangle' points='1,0 0,1 0,0.1 0.1,0'/>
            </svg>
        </div>
        <svg class='nav-button rotate' id='first-button' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 58 13'>
            <a href='../about'>
                <polygon class='white-shape' points='3 0 0 4.5 8 13 55 13 58 8.55 50 0 3 0'/>
                <text x='11' y='9' fill='#161616' font-size='6px'>About</text>
            </a>
        </svg>
        <svg class='nav-button rotate no-pointer' id='second-button' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 58 13'>
            <polygon class='red-shape' points='3 0 0 4.5 8 13 55 13 58 8.55 50 0 3 0'/>
            <text x='11' y='9' fill='white' font-size='6px'>Papers</text>
        </svg>
        <svg class='nav-button rotate' id='third-button' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 58 13'>
            <a href='../resource'>
                <polygon class='white-shape' points='3 0 0 4.5 8 13 55 13 58 8.55 50 0 3 0'/>
                <text x='11' y='9' fill='#161616' font-size='6px'>Resource</text>
            </a>
        </svg>
        <svg class='nav-button rotate' id='fourth-button' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 58 13'>
            <a href='../demo'>
                <polygon class='white-shape' points='3 0 0 4.5 8 13 55 13 58 8.55 50 0 3 0'/>
                <text x='11' y='9' fill='#161616' font-size='6px'>Demo</text>
            </a>
        </svg>
        <div class='nav-button-small' id='secret-button-right'>
            <svg class='tight' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'>
                <polygon class='nav-triangle' points='1,0 0,1 0.9,1 1,0.9'/>
            </svg>
        </div>
    </nav>
    <main class='text-box'>
        <p class='section-title'>Journal Articles</p>
        <p class='reference'><a href='https://claracolombatto.com/' target='_blank' rel='noopener noreferrer'>Colombatto, C.</a>, Chen, Y. -C., & <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a> (2024). Perceived gaze dynamics in social interactions can alter (and even reverse) the perceived temporal order of events. <em>Cognition, 247</em>:105745, 1–8. <a href='../files/papers/Colombatto_Chen_Scholl_2024_Cog_gazeDeflectionTOJ.pdf' target='_blank' rel='noopener noreferrer'>[Full Text]</a> <a href='../files/papers/Colombatto_Chen_Scholl_2024_Cog_gazeDeflectionTOJ_suppl.xlsx' target='_blank' rel='noopener noreferrer'>[Supplement]</a></p>
        <p class='reference'>Chen, Y. -C., <a href='https://www.gla.ac.uk/schools/psychology/staff/frankpollick/' target='_blank' rel='noopener noreferrer'>Pollick, F.</a>, & <a href='http://cvl.psych.ucla.edu/people/' target='_blank' rel='noopener noreferrer'>Lu, H.</a> (2023). Aesthetic preferences for prototypical movements in human actions. <em>Cognitive Research: Principles and Implications, 8</em>:55, 1–13. <a href='../files/papers/Chen_Pollick_Lu_2023_CRPI_walkingPrototypeEffect.pdf' target='_blank' rel='noopener noreferrer'>[Full Text]</a> <a href='https://doi.org/10.17605/OSF.IO/87G3E' target='_blank' rel='noopener noreferrer'>[OSF]</a></p>
        <p class='reference'>Chen, Y. -C., <a href='https://www.gla.ac.uk/schools/psychology/staff/frankpollick/' target='_blank' rel='noopener noreferrer'>Pollick, F.</a>, & <a href='http://cvl.psych.ucla.edu/people/' target='_blank' rel='noopener noreferrer'>Lu, H.</a> (2022). Aesthetic preferences for causality in biological movements arise from visual processes. <em>Psychonomic Bulletin & Review, 29, </em>1803–1811. <a href='../files/papers/Chen_Pollick_Lu_2022_PB&R_AnimacyCausalityAesthetics.pdf' target='_blank' rel='noopener noreferrer'>[Full Text]</a> <a href='../demo/ani-aes/' target='_blank' rel='noopener noreferrer'>[Demo]</a> <a href='https://doi.org/10.17605/OSF.IO/WTSRF' target='_blank' rel='noopener noreferrer'>[OSF]</a></p>
        <p class='reference'>Chen, Y. -C., <a href='http://arturodeza.wikidot.com/' target='_blank' rel='noopener noreferrer'>Deza, A.</a>, & <a href='https://konklab.fas.harvard.edu/' target='_blank' rel='noopener noreferrer'>Konkle, T.</a> (2022). How big should this object be? Perceptual influences on viewing-size preferences. <em>Cognition, 225</em>:105114, 1–11. <a href='../files/papers/Chen_Deza_Konkle_2022_Cog_texformSizePreference.pdf' target='_blank' rel='noopener noreferrer'>[Full Text]</a> <a href='https://doi.org/10.17605/OSF.IO/PQVSR' target='_blank' rel='noopener noreferrer'>[OSF]</a></p>
        <p class='reference'>Chen, Y. -C., <a href='https://andrew-chang.org/' target='_blank' rel='noopener noreferrer'>Chang, A.</a>, <a href='https://cablab.uchicago.edu/people/' target='_blank' rel='noopener noreferrer'>Rosenberg, M. D.</a>, Feng, D., <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a>, & <a href='https://experts.mcmaster.ca/display/ljt' target='_blank' rel='noopener noreferrer'>Trainor, L. J.</a> (2022). "Taste typicality" is a foundational and multi-modal dimension of ordinary aesthetic experience. <em>Current Biology, 32,</em> 1837–1842. <a href='../files/papers/Chen_etal_2022_CB_crossmodelTasteTypicality.pdf' target='_blank'>[Full Text]</a> <a href='https://yi-chia-chen.github.io/taste-typicality-demo-expt/' target='_blank' rel='noopener noreferrer'>[Experiment Demo]</a> <a href='https://doi.org/10.17605/OSF.IO/T925Q' target='_blank' rel='noopener noreferrer'>[OSF]</a></p>
        <p class='reference'>Forman, I. R., Chen, Y. -C., <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a>, & <a href='https://scorsese.wjh.harvard.edu/George/' target='_blank' rel='noopener noreferrer'>Alvarez, G. A.</a> (2021). The center cannot hold: Variations of frame width help to explain the ‘inward bias’ in aesthetic preferences. <em>Attention, Perception, & Psychophysics, 83,</em> 2151–2158. <a href='../files/papers/Forman_Chen_etal_2021_AP&P_TheCenterCannotHold.pdf' target='_blank'>[Full Text]</a> <a href='https://doi.org/10.17605/OSF.IO/27VNP' target='_blank' rel='noopener noreferrer'>[OSF]</a></p>
        <p class='reference'><a href='https://claracolombatto.com/' target='_blank' rel='noopener noreferrer'>Colombatto, C.</a>, Chen, Y. -C., & <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a> (2020). ‘Gaze deflection’ reveals how gaze cueing is tuned to extract the mind behind the eyes. <em>Proceedings of the National Academy of the United States of America, 117,</em> 19825–19829. <a href='../files/papers/Colombatto_Chen_Scholl_2020_PNAS_gazeDeflection.pdf' target='_blank'>[Full Text]</a> <a href='http://perception.yale.edu/gaze-deflection/' target='_blank' rel='noopener noreferrer'>[Demo]</a> <a href='../files/papers/Colombatto_Chen_Scholl_2020_PNAS_gazeDeflection_suppl.zip'>[Supplement]</a></p>
        <p class='reference'>Yousif, S. R., Chen, Y. -C., & <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a> (2020). Systematic angular biases in the representation of visual space. <em>Attention, Perception, & Psychophysics, 82,</em> 3124–3143. <a href='../files/papers/Yousif_Chen_Scholl_2020_AP&P_angularBiasesInVisualSpace.pdf' target='_blank'>[Full Text]</a></p>
        <p class='reference'>Chen, Y. -C., <a href='https://claracolombatto.com/' target='_blank' rel='noopener noreferrer'>Colombatto, C.</a>, & <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a> (2018). Looking into the future: An inward bias in aesthetic experience driven only by gaze cues. <em>Cognition, 176,</em> 209–214. <a href='../files/papers/Chen_Colombatto_Scholl_2018_Cog_LookingIntoTheFuture.pdf' target='_blank'>[Full Text]</a> <a href='http://perception.yale.edu/Brian/demos/Aesthetics-InwardBiasGaze.html' target='_blank' rel='noopener noreferrer'>[Demo]</a></p>
        <p class='reference'>Chen, Y. -C., & <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a> (2016). The perception of history: Seeing causal history in static shapes induces illusory motion perception. <em>Psychological Science, 27,</em> 923–930. <a href='../files/papers/Chen_Scholl_2016_PsychSci_shapeHistory.pdf' target='_blank'>[Full Text]</a> <a href='http://perception.yale.edu/Brian/demos/CausalHistory-AM.html' target='_blank' rel='noopener noreferrer'>[Demo]</a></p>
        <p class='reference'>Chen, Y. -C., & <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a> (2014). Seeing and liking: Biased perception of ambiguous figures consistent with the 'inward bias' in aesthetic preferences. <em>Psychonomic Bulletin & Review, 21,</em> 1444–1451. <a href='../files/papers/Chen_Scholl_2014_PB&R_inwardAmbiguous.pdf' target='_blank'>[Full Text]</a></p>
        <p class='reference'>Chen, Y. -C., & <a href='http://epa.psy.ntu.edu.tw/SuLingYeh_eng.html' target='_blank' rel='noopener noreferrer'>Yeh, S. -L.</a> (2012). Look into my eyes and I will see you: Unconscious processing of human gaze. <em>Consciousness & Cognition, 21,</em> 1703–1710. <a href='../files/papers/Chen_Yeh_2012_C&C_unconsciousGaze.pdf' target='_blank'>[Full Text]</a></p>

        <p class='section-title'>Manuscripts</p>
        <p class='reference'>Chen, Y. -C., Fu, S., Feng, D., Taylor, M., Chang, J., Chi, X., & <a href='http://cvl.psych.ucla.edu/people/' target='_blank' rel='noopener noreferrer'>Lu, H.</a> (under review). Prototype preference is a principle of aesthetics for real-world scene perception.</p>
        <p class='reference'><a href='https://claracolombatto.com/' target='_blank' rel='noopener noreferrer'>Colombatto, C.</a>, Chen, Y. -C., <a href='https://www.nssrperception.com/' target='_blank' rel='noopener noreferrer'>van Buren, B.</a>, & <a href='http://perception.yale.edu/Brian/' target='_blank' rel='noopener noreferrer'>Scholl, B. J.</a> (under review). Foundations of social perception: Eye contact or ‘mind contact’?</p>

        <p class='section-title'>Conference Papers</p>
        <p class='reference-conf'>Chen, Y. -C, <a href='https://www.gla.ac.uk/schools/psychology/staff/frankpollick/' target='_blank' rel='noopener noreferrer'>Pollick, F.</a>, & <a href='http://cvl.psych.ucla.edu/people/' target='_blank' rel='noopener noreferrer'>Lu, H.</a> (2021). Aesthetic experience is influenced by causality in biological movements. Talk presented at the 2021 Annual Meeting of the <em>Cognitive Science Society (CogSci)</em>, 7/28, World Wide Web, Earth. <a href='https://escholarship.org/uc/item/05b2r0m5' target='_blank' rel='noopener noreferrer'>[Full Text]</a> <a href='../demo/ani-aes/' target='_blank'>[Demo]</a></p>
        <p class='reference-conf'><a href='http://arturodeza.wikidot.com/' target='_blank' rel='noopener noreferrer'>Deza, A.</a>, Chen, Y. -C, <a href='https://www.brialong.com/' target='_blank' rel='noopener noreferrer'>Long, B.</a>, & <a href='https://konklab.fas.harvard.edu/' target='_blank' rel='noopener noreferrer'>Konkle, T.</a> (2019). Accelerated texforms: Alternative methods for generating unrecognizable object images with preserved mid-level features. Poster presented at the <em>Conference on Cognitive Computational Neuroscience (CCN)</em>, 9/15, Berlin, Germany. <a href='https://ccneuro.org/2019/proceedings/0000879.pdf' target='_blank' rel='noopener noreferrer'>[Full Text]</a> <a href='../files/posters/Deza_Chen_Long_Konkle_2018_CCN_FastTexFormsPoster.pdf' target='_blank'>[Poster]</a> <a href='https://github.com/ArturoDeza/Fast-Texforms' target='_blank' rel='noopener noreferrer'>[Code]</a></p>
        <p class='reference-conf'>Huang, T. -H., Kao, C. -T, Chen, Y. -C., <a href='http://epa.psy.ntu.edu.tw/SuLingYeh_eng.html' target='_blank' rel='noopener noreferrer'>Yeh, S. -L.</a>, & Chen, H. H. (2012). A visibility model for quality assessment of dimmed images. Poster presented at the 4th <em>International Workshop on Quality of Multimedia Experience (QoMEX)</em>, 7/06, Yarra Valley, Australia. <a href='../files/papers/Huang_etal_2012_dimmedQuality.pdf' target='_blank'>[Full Text]</a></p>

        <p class='section-title'>Conference Presentations</p>
        <p class='reference-conf'>Chen, Y. -C., Fu, S., Feng, D., Taylor, M., Chang, J., Chi, X., & Lu, H. (2023). The prototype effect in aesthetic preferences for visual scenes: A computational account. Poster presented at the 2023 Meeting of <em>Vision Sciences Society (VSS)</em>, 5/22, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/jov.23.9.5023' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Yun, Y., Fu, S., Chen, Y. -C., Lu, H. (2023). Force representations support social perception of moving shapes. Poster presented at the 2023 Meeting of <em>Vision Sciences Society (VSS)</em>, 5/24, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/jov.23.9.4839' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chang, J., Chen, Y. -C., & Lu, H. (2022). What do we see in a reflection? Seeing chirality correlates with aesthetic experience. Poster presented at the 2022 Virtual Meeting of <em>Vision Sciences Society (V-VSS)</em>, 6/1, World Wide Web, Earth.</p>
        <p class='reference-conf'>Chen, Y. -C., Pollick, F. E., & Lu, H. (2022). What makes an elegant walk: Aesthetic preferences for prototypical movements in human walking actions. Talk given at the 2022 Meeting of <em>Vision Sciences Society (VSS)</em>, 5/16, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/jov.22.14.3097' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Fu, S., Chen. Y. -C., Colombatto, C., Lu, H. (2022). Visual impressions of social avoidance from moving shapes. Poster presented at the 2022 Meeting of <em>Vision Sciences Society (VSS)</em>, 5/14, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/jov.22.14.3693' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., Pollick, F. E., & Lu, H. (2021). Aesthetic experience is influenced by causality in biological movements. Poster presented at the 2021 Virtual Meeting of <em>Vision Sciences Society (V-VSS)</em>, 5/24, World Wide Web, Earth. <a href='../files/posters/Chen_Pollick_Lu_2021_VVSS_animacyCausality&Aesthetics.pdf' target='_blank'>[Poster]</a> <a href='../files/videos/Chen_Pollick_Lu_2021_VVSS_animacyCausality&Aesthetics.mp4' target='_blank'>[Walkthrough]</a> <a href='https://doi.org/10.1167/jov.21.9.1916' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Colombatto, C., Chen, Y. -C., & Scholl, B. J. (2021). Gazing to look vs. gazing to think: Gaze cueing is modulated by the perception of others’ external vs. internal attention. Poster presented at the 2021 Virtual Meeting of <em>Vision Sciences Society (V-VSS)</em>, 5/23, World Wide Web, Earth. <a href='https://doi.org/10.1167/jov.21.9.2800' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., Deza, A., & Konkle, T. (2020). How big should this object be? Perceptual influences on viewing-size preferences. Poster presented at the 2020 Virtual Meeting of <em>Vision Sciences Society (V-VSS)</em>, 6/19-24, World Wide Web, Earth. <a href='../files/posters/Chen_Deza_Konkle_2020_VVSS_sizePreference.pdf' target='_blank'>[Poster]</a> <a href='../files/videos/Chen_Deza_Konkle_2020_VVSS_sizePreferencePresentation.mp4' target='_blank'>[Walkthrough]</a> <a href='https://doi.org/10.1167/jov.20.11.428' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., Deza, A., & Konkle, T. (2020). How big should this object be? Perceptual influences on viewing-size preferences. Talk given at the 6th <em>Visual Properties Driving Visual Preference (VPDVP)</em> Workshop, 6/12, World Wide Web, Earth.</p>
        <p class='reference-conf'>Chen, Y. -C., Chang, A., Rosenberg, M. D., Scholl, B. J., & Trainor, L. J. (2019). Are you the sort of person who would like this? Quantifying the typicality of aesthetic taste across seeing and hearing. Talk given at the 2019 Annual Meeting of <em>Vision Sciences Society (VSS)</em>, 5/20, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/19.10.174b' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Yousif, S. R., Chen, Y. -C., & Scholl, B. J. (2019). Systematic biases in the representation of visual space. Poster presented at the 2019 Annual Meeting of <em>Vision Sciences Society (VSS)</em>, 5/20, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/19.10.202b' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., Colombatto, C., & Scholl, B. J. (2018). Looking into the future: An inward bias in aesthetic experience driven only by gaze cues. Poster presented at the 2018 Annual Meeting of <em>Vision Sciences Society (VSS)</em>, 5/23, St. Pete Beach, FL, USA. <a href='../files/posters/Chen_Colombatto_Scholl_2018_VSS_gazeInwardBias.pdf' target='_blank'>[Poster]</a> <a href='https://doi.org/10.1167/18.10.1333' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Yousif, S., Chen, Y. -C., & Scholl, B. J. (2018). The origin of spatial biases: Memory, perception, or action? Poster presented at the 2018 Annual Meeting of <em>Vision Sciences Society (VSS)</em>, 5/23, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/18.10.1324' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Colombatto, C., Chen, Y. -C., & Scholl, B. J. (2018). Gaze cueing is tuned to extract the mind behind the gaze: Investigations of 'gaze deflection'. Talk given at the 2018 Annual Meeting of <em>Vision Sciences Society (VSS)</em>, 5/19, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/18.10.197' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Colombatto, C., Chen, Y. -C., & Scholl, B. J. (2017). Gaze cueing is tuned to extract the mind behind the gaze: Investigations of ‘gaze deflection’. Poster presented at the annual meeting of the <em>European Conference on Visual Perception (ECVP)</em>, 8/29, Berlin, Germany.</p>
        <p class='reference-conf'>Chen, Y. -C., Raila, H., & Scholl, B. J. (2017). Sad minds seeking happy stimuli: Trait happiness predicts how quickly happy faces reach visual awareness. Poster presented at the annual meeting of <em>Vision Sciences Society (VSS)</em>, 5/23, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/17.10.1210' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Raila, H., Chen, Y. -C., & Scholl, B. J. (2017). Unhappy people quickly promote happy faces into awareness. Talk presented at the annual meeting of the <em>Society for Affective Science (SAS)</em>, 4/29, Boston, MA, USA.</p>
        <p class='reference-conf'>Chen, Y. -C., & Scholl, B. J. (2015). Seeing history: The perception of causal history induces illusory motion perception in static shapes. Talk given at the 11th <em>Asia-Pacific Conference on Vision (APCV)</em>, 7/11,Nanyang Technological University, Singapore. <a href='../files/abstracts/Chen_Scholl_2015_APCV_seeingHistoryAbstract.html' target='_blank'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., & Scholl, B. J. (2015). The perception of history: Seeing causal history in static shapes is powerful enough to induce illusory motion perception. Poster presented at the 2015 Annual Meeting of <em>Vision Sciences Society (VSS)</em>, 5/19, St. Pete Beach, FL, USA. <a href='../files/posters/Chen_Scholl_2015_VSS_seeingHistoryPoster.pdf' target='_blank'>[Poster]</a> <a href='https://doi.org/10.1167/15.12.1035' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., & Scholl, B. J. (2014). Aesthetic influences on visual awareness?: An 'inward bias' in inattentional blindness. Talk given at the 10th <em>Asia-Pacific Conference on Vision (APCV)</em>, 7/21, Takamatsu, Japan.</p>
        <p class='reference-conf'>Chen, Y. -C., & Scholl, B. J. (2014). Seeing and liking from the outside in: Consistent inward biases in visual perception and aesthetic preferences. Poster presented at the 2014 Annual Meeting of <em>Vision Sciences Society (VSS)</em>, 5/17, St. Pete Beach, FL, USA. <a href='https://doi.org/10.1167/14.10.246' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., & Scholl, B. J. (2013). Seeing and liking: Biased perception of ambiguous figures based on aesthetic preferences for how objects should face within a frame. Poster presented at the 2013 Annual Meeting of <em>Vision Sciences Society (VSS)</em>, 5/10, Naples, FL, USA. <a href='../files/posters/Chen_Scholl_2013_VSS_inwardAmbiguousPoster.pdf' target='_blank'>[Poster]</a> <a href='https://doi.org/10.1167/13.9.59' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., & Yeh, S. -L. (2011). Dissociating attention and audiovisual integration in the sound-facilitatory effect on metacontrast masking. Poster presented at the 12th <em>International Multisensory Research Forum (IMRF)</em>, 10/19, Fukuoka, Japan. <a href='../files/posters/Chen_Yeh_2011_IMRF_maskingPoster.pdf' target='_blank'>[Poster]</a> <a href='https://doi.org/10.1068/ic909' target='_blank' rel='noopener noreferrer'>[Abstract]</a></p>
        <p class='reference-conf'>Chen, Y. -C., & Yeh, S. -L. (2011). Orienting or intention? Unconscious processing of human gaze. Talk given at the 15th Annual Meeting of the <em>Association for the Scientific Study of Consciousness (ASSC)</em>, 6/12, Kyoto, Japan. <a href='../files/abstracts/Chen_Yeh_2011_ASSC_unconsciousGazeAbstract.html' target='_blank'>[Abstract]</a></p>
    </main>
    <footer>
        <a class='footer-button' href='https://scholar.google.com/citations?user=8DzbEt8AAAAJ' target='_blank' rel='noopener noreferrer'>
            <i class='ai ai-google-scholar footer-icon'></i>
            <svg class='tight' xmlns='http://www.w3.org/2000/svg'  viewBox='0 0 22 19.32'>
                <polygon class='hexagon' points='6,1 16,1, 21,9.66 16,18.32 6,18.32 1,9.66'/>
            </svg>
        </a>
        <a class='footer-button' href='https://www.researchgate.net/profile/Yi-Chia_Chen' target='_blank' rel='noopener noreferrer'>
            <i class='ai ai-researchgate footer-icon'></i>
            <svg class='tight' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 22 19.32'>
                <polygon class='hexagon' points='6,1 16,1, 21,9.66 16,18.32 6,18.32 1,9.66'/>
            </svg>
        </a>
        <a class='footer-button' href='https://github.com/Yi-Chia-Chen' target='_blank' rel='noopener noreferrer'>
            <i class='fab fa-github footer-icon'></i>
            <svg class='tight' xmlns='http://www.w3.org/2000/svg' viewBox='0 0 22 19.32'>
                <polygon class='hexagon' points='6,1 16,1, 21,9.66 16,18.32 6,18.32 1,9.66'/>
            </svg>
        </a>
    </footer>
    <script>
        var sc_project = 12015468;
        var sc_invisible = 1;
        var sc_security = '035108ae';
    </script>
    <script src='https://www.statcounter.com/counter/counter.js' async></script>
</body>

</html>